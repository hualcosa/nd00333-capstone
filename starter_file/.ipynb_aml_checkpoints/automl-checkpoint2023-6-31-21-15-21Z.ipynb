{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment, Dataset, Datastore\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "import logging\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.automl.core.forecasting_parameters import ForecastingParameters\n",
        "from azureml.widgets import RunDetails\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1690828593911
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "\n",
        "This dataset contains information about sales of stores from a Retail Company, like Walmart.The dataset contains historical weekly sales values(target column) and other\n",
        "supporting variables for that period like:\n",
        "1. Store identifier\n",
        "2. average temperature in the week \n",
        "3. whether or not there was a holiday during the week\n",
        "4. fuel price\n",
        "5. Consumer Price Index(CPI)\n",
        "6. Unemployment rate \n",
        "\n",
        "The goal of this task is to use historical data to forecast sales numbers for the next four weeks(month). These predictions are going to support\n",
        "finance and business people in the company to manage the store's inventory. <br>\n",
        "This dataset comes from Kaggle and further details about it can be found [here.](https://www.kaggle.com/datasets/asahu40/walmart-data-analysis-and-forcasting) "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data.\n",
        "I have downloaded the dataset from Kaggle and uploaded it to this notebook's working directory. <br>Now I am going to import it with the help of the\n",
        "Dataset class.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'capstone-project'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1690824258944
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datastore = Datastore.get(ws, datastore_name='workspaceworkingdirectory')"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690824263690
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset.Tabular.from_delimited_files(path=(datastore, \"Users/hualcosa/nd00333-capstone/data/Walmart Data Analysis and Forcasting.csv\"))\n",
        "type(data)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "azureml.data.tabular_dataset.TabularDataset"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690824271793
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting data as pandas dataframe for local experiment\n",
        "df = data.to_pandas_dataframe()\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "   Store       Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n0      1 2010-02-05    1643690.90             0        42.31       2.572   \n1      1 2010-02-12    1641957.44             1        38.51       2.548   \n2      1 2010-02-19    1611968.17             0        39.93       2.514   \n3      1 2010-02-26    1409727.59             0        46.63       2.561   \n4      1 2010-03-05    1554806.68             0        46.50       2.625   \n\n          CPI  Unemployment  \n0  211.096358         8.106  \n1  211.242170         8.106  \n2  211.289143         8.106  \n3  211.319643         8.106  \n4  211.350143         8.106  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>Date</th>\n      <th>Weekly_Sales</th>\n      <th>Holiday_Flag</th>\n      <th>Temperature</th>\n      <th>Fuel_Price</th>\n      <th>CPI</th>\n      <th>Unemployment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2010-02-05</td>\n      <td>1643690.90</td>\n      <td>0</td>\n      <td>42.31</td>\n      <td>2.572</td>\n      <td>211.096358</td>\n      <td>8.106</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2010-02-12</td>\n      <td>1641957.44</td>\n      <td>1</td>\n      <td>38.51</td>\n      <td>2.548</td>\n      <td>211.242170</td>\n      <td>8.106</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2010-02-19</td>\n      <td>1611968.17</td>\n      <td>0</td>\n      <td>39.93</td>\n      <td>2.514</td>\n      <td>211.289143</td>\n      <td>8.106</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2010-02-26</td>\n      <td>1409727.59</td>\n      <td>0</td>\n      <td>46.63</td>\n      <td>2.561</td>\n      <td>211.319643</td>\n      <td>8.106</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2010-03-05</td>\n      <td>1554806.68</td>\n      <td>0</td>\n      <td>46.50</td>\n      <td>2.625</td>\n      <td>211.350143</td>\n      <td>8.106</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690824276339
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - reformat target column and windows (MAYBE)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# registering dataset so It can be used for automl experiment\n",
        "data.register(ws, name=\"sales_forecasting\", description=\"capstone project dataset\")\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "{\n  \"source\": [\n    \"('workspaceworkingdirectory', 'Users/hualcosa/nd00333-capstone/data/Walmart Data Analysis and Forcasting.csv')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\",\n    \"ParseDelimited\",\n    \"DropColumns\",\n    \"SetColumnTypes\"\n  ],\n  \"registration\": {\n    \"id\": \"a8489742-86d6-4cec-b52b-6098c3e55e4a\",\n    \"name\": \"sales_forecasting\",\n    \"version\": 1,\n    \"description\": \"capstone project dataset\",\n    \"workspace\": \"Workspace.create(name='capstone-project', subscription_id='d2706c67-acfc-4bd3-9067-3ff6ac190bc9', resource_group='capstone-project')\"\n  }\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690813986289
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now that we have registered the dataset, it appears as an data asset, and can be used as an input source to the automl experiment.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a name for your CPU cluster\n",
        "cpu_cluster_name = \"capstone-cluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # To use a different region for the compute, add a location='<region>' parameter\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', \n",
        "                                                            min_nodes=1,\n",
        "                                                           max_nodes=4)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
        "\n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "InProgress..\nSucceededProvisioning operation finished, operation \"Succeeded\"\nSucceeded.................\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690824388147
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## AutoML Configuration\n",
        "In order to run the the AutoML experiment, we set the following parameters:\n",
        "- compute_target where the experiment is going to run. In our case, the compute cluster, we just created\n",
        "- primary metric: The metric we want to optimize. Since we're dealing with a time series forecasting problem, Normalized root mean squared error is a great pick\n",
        "- experiment_timeout_minutes: Maximum time that the experiment can run. I want the experiment to run for 60 minutes maximum.\n",
        "- enable_early_stopping: Set it to True to allow the training iteration to prematurely end if the model scores are not improving\n",
        "- n_cross_validations and cv_step_size: cross validation parameters. Set it to \"auto\" so automl job can investigate how to best split the data to perform cross validation\n",
        "- enable_voting_ensenble and enable_dnn: Set it to true to consider voting ensemble models as well as Dense Neural Networks when searching for the best model.\n",
        "- Verbosity: set logging verbosity to INFO\n",
        "- Forecasting parameters: Object containing info about the forecasting job that needs to be performed. In our specifc case, it specifies what is the name of the time column, <br>\n",
        "what is the forecast horizon(4 weeks) and what column(s) identify the time series"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "   Store       Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n0      1 2010-02-05     1643690.9             0        42.31       2.572   \n\n          CPI  Unemployment  \n0  211.096358         8.106  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>Date</th>\n      <th>Weekly_Sales</th>\n      <th>Holiday_Flag</th>\n      <th>Temperature</th>\n      <th>Fuel_Price</th>\n      <th>CPI</th>\n      <th>Unemployment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2010-02-05</td>\n      <td>1643690.9</td>\n      <td>0</td>\n      <td>42.31</td>\n      <td>2.572</td>\n      <td>211.096358</td>\n      <td>8.106</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690826609987
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forecasting_parameters = ForecastingParameters(time_column_name='Date', \n",
        "                                               forecast_horizon=4,\n",
        "                                               time_series_id_column_names='Store')\n",
        "                                               \n",
        "automl_settings = {'compute_target': cpu_cluster,\n",
        "                    'primary_metric':'normalized_root_mean_squared_error',\n",
        "                    'experiment_timeout_minutes': 60,\n",
        "                    'enable_early_stopping': True,\n",
        "                    'n_cross_validations': \"auto\", # Could be customized as an integer\n",
        "                    'cv_step_size' : \"auto\", # Could be customized as an integer\n",
        "                    'enable_voting_ensemble': True,\n",
        "                    'enable_dnn': True,\n",
        "                    'verbosity': logging.INFO,\n",
        "                    'forecasting_parameters': forecasting_parameters}\n",
        "\n",
        "automl_config = AutoMLConfig(\n",
        "                             task='forecasting',\n",
        "                             training_data=data,\n",
        "                             label_column_name='Weekly_Sales',\n",
        "                             **automl_settings\n",
        "                             )"
      ],
      "outputs": [],
      "execution_count": 55,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690830921999
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "automl_run = experiment.submit(automl_config, show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submitting remote run.\nNo run_configuration provided, running on capstone-cluster with default configuration\nRunning on remote compute: capstone-cluster\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>capstone-project</td><td>AutoML_5e8945c3-9c9b-4df1-8b84-ecd7ff691c6b</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_5e8945c3-9c9b-4df1-8b84-ecd7ff691c6b?wsid=/subscriptions/d2706c67-acfc-4bd3-9067-3ff6ac190bc9/resourcegroups/capstone-project/workspaces/capstone-project&amp;tid=9a8d38e4-12e5-43af-8de6-e9f9c0e696da\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nCurrent status: DatasetFeaturization. Beginning to featurize the CV split.\nCurrent status: ModelSelection. Beginning model selection.\n\n********************************************************************************************\nDATA GUARDRAILS: \n\nTYPE:         Time Series ID detection\nSTATUS:       PASSED\nDESCRIPTION:  The data set was analyzed, and no duplicate time index were detected.\n              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration\n\n********************************************************************************************\n\nTYPE:         Frequency detection\nSTATUS:       PASSED\nDESCRIPTION:  The time series was analyzed, all data points are aligned with detected frequency.\n              Learn more about data preparation for time-series forecasting: https://aka.ms/AutomatedMLDataPreparation\n\n********************************************************************************************\n\nTYPE:         Data size validation for TCNForecaster model\nSTATUS:       PASSED\nDESCRIPTION:  The input data set has enough data points after pre-processing to train TCNForecaster model\n              \nDETAILS:      For training TCNForecaster model, the input dataset after pre-processing must have at least 500 data points for single time series data and 1000 data points for multiple time series data.\n+--------------------------------+-------------------------------+\n|Rows count before pre-processing|Rows count after pre-processing|\n+================================+===============================+\n|6435                            |6435                           |\n+--------------------------------+-------------------------------+\n\n********************************************************************************************\n\nTYPE:         Missing feature values imputation\nSTATUS:       PASSED\nDESCRIPTION:  No feature missing values were detected in the training data.\n              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n\n********************************************************************************************\n\nTYPE:         Short series handling\nSTATUS:       PASSED\nDESCRIPTION:  Automated ML detected enough data points for each series in the input data to continue with training.\n              Learn more about short series handling: https://aka.ms/AutomatedMLShortSeriesHandling\n\n********************************************************************************************\n\nTYPE:         Automatic cross validation\nSTATUS:       DONE\nDESCRIPTION:  Cross validation parameter(s) were automatically set for your dataset.\n              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration\nDETAILS:      If n_cross_validations and/or cv_step_size is not specified, Automated ML will determine those cross validation parameters automatically for you.\n+--------------------------------+----------------------------------------------------------------+\n|Number of cross validation folds|Number of periods between two consecutive cross validation folds|\n+================================+================================================================+\n|5                               |4                                                               |\n+--------------------------------+----------------------------------------------------------------+\n\n********************************************************************************************\n\n********************************************************************************************\nITER: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************\n\n ITER   PIPELINE                                       DURATION            METRIC      BEST\n"
        }
      ],
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1690834881887
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(automl_run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'sâ€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34782f3b9aa349129cbe4d3f3ee646f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"loading\": true}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 58,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690835474305
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431425670
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Save the best model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431426111
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431435189
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submission Checklist**\n",
        "- I have registered the model.\n",
        "- I have deployed the model with the best accuracy as a webservice.\n",
        "- I have tested the webservice by sending a request to the model endpoint.\n",
        "- I have deleted the webservice and shutdown all the computes that I have used.\n",
        "- I have taken a screenshot showing the model endpoint as active.\n",
        "- The project includes a file containing the environment details.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}