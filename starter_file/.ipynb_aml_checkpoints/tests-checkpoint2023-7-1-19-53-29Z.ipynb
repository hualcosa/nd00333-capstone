{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset, Datastore\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "\n",
        "def get_data():\n",
        "    subscription_id = 'd2706c67-acfc-4bd3-9067-3ff6ac190bc9'\n",
        "    resource_group = 'capstone-project'\n",
        "    workspace_name = 'capstone-project'\n",
        "\n",
        "    workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
        "\n",
        "    datastore = Datastore.get(workspace, \"workspaceworkingdirectory\")\n",
        "    dataset = Dataset.Tabular.from_delimited_files(path=(datastore, 'Users/hualcosa/nd00333-capstone/data/Walmart Data Analysis and Forcasting.csv'))\n",
        "    df = dataset.to_pandas_dataframe() \n",
        "    return df"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1690914648196
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(df):\n",
        "    '''\n",
        "    This function formats the dataframe, adding past 8 weeks of sales as lagged features\n",
        "    and 4 weeks of future sales as the label column.\n",
        "\n",
        "    Return:\n",
        "    X. Training data with features + lagged sales\n",
        "    y. vector with the next 4 weeks of sales\n",
        "    '''\n",
        "    \n",
        "    df_with_windows = []\n",
        "    for store_num in df.Store.unique():\n",
        "        store_df = df[df.Store == store_num].copy()\n",
        "        # making lag features\n",
        "        for i in range(1, 9):\n",
        "            store_df[f'Weekly_Sales_t-{i}'] = store_df['Weekly_Sales'].shift(i)\n",
        "        # making future_time_steps\n",
        "        for i in range(1,4):\n",
        "            store_df[f'Weekly_Sales_t+{i}'] = store_df['Weekly_Sales'].shift(-i)\n",
        "\n",
        "        df_with_windows.append(store_df)\n",
        "\n",
        "    df_with_windows = pd.concat(df_with_windows).dropna()\n",
        "    # renaming first future value, to follow the same pattern as the other columns\n",
        "    df_with_windows.rename(columns={\"Weekly_Sales\":\"Weekly_Sales_t+0\"}, inplace=True)\n",
        "    df_with_windows = df_with_windows[['Store', 'Date', 'Holiday_Flag', 'Temperature',\n",
        "                                        'Fuel_Price', 'CPI', 'Unemployment', 'Weekly_Sales_t-1',\n",
        "                                        'Weekly_Sales_t-2', 'Weekly_Sales_t-3', 'Weekly_Sales_t-4',\n",
        "                                        'Weekly_Sales_t-5', 'Weekly_Sales_t-6', 'Weekly_Sales_t-7',\n",
        "                                        'Weekly_Sales_t-8', 'Weekly_Sales_t+0','Weekly_Sales_t+1', 'Weekly_Sales_t+2',\n",
        "                                        'Weekly_Sales_t+3']]\n",
        "\n",
        "    # separate by store, train_test_split, and then join data again\n",
        "    x_train, x_val, y_train, y_val = [], [], [], []\n",
        "\n",
        "    for store_num in df_with_windows.Store.unique():\n",
        "        store_df = df_with_windows[df_with_windows.Store == store_num].copy()\n",
        "        # future columns filter\n",
        "        ftr = store_df.columns.str.match(r'.+t\\+\\d')\n",
        "        # making label vector\n",
        "        y_store = store_df.loc[:, ftr].apply(lambda row: list(row), axis=1).tolist()\n",
        "        # convert list to numpy array format\n",
        "        y_store = np.array(y_store)\n",
        "        # making training data\n",
        "        X_store = store_df.drop(columns='Date').values\n",
        "        x_train_store, x_val_store, y_train_store, y_val_store = train_test_split(X_store, y_store, test_size=0.2, shuffle=False, random_state=96)\n",
        "        \n",
        "        # appending to final results\n",
        "        x_train.append(x_train_store)\n",
        "        x_val.append(x_val_store)\n",
        "        y_train.append(y_train_store)\n",
        "        y_val.append(y_val_store)\n",
        "\n",
        "    x_train = np.concatenate(x_train)\n",
        "    x_val = np.concatenate(x_val)\n",
        "    y_train = np.concatenate(y_train)\n",
        "    y_val = np.concatenate(y_val)\n",
        "\n",
        "    return x_train, x_val, y_train, y_val\n"
      ],
      "outputs": [],
      "execution_count": 115,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690904486219
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info('Getting data...')\n",
        "df = get_data()\n",
        "logging.info('formatting data...')\n",
        "x_train, x_val, y_train, y_val = process_data(df)"
      ],
      "outputs": [],
      "execution_count": 116,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690904497031
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 117,
          "data": {
            "text/plain": "((4725, 18), (1215, 18), (4725, 4), (1215, 4))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 117,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690904515131
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(x_train, y_train, kwargs):\n",
        "    '''\n",
        "    This function receives the processed X, y values and fits a multiple output XGBRegressor to it.\n",
        "\n",
        "    Returns: the fitted model\n",
        "    '''\n",
        "    #Define the estimator\n",
        "    estimator = xgb.XGBRegressor(\n",
        "        objective = 'reg:squarederror',\n",
        "        **kwargs\n",
        "        )\n",
        "\n",
        "    # Define the model\n",
        "    my_model = MultiOutputRegressor(estimator = estimator, n_jobs = -1)\n",
        "    my_model.fit(x_train, y_train)\n",
        "\n",
        "    return my_model"
      ],
      "outputs": [],
      "execution_count": 120,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690905612124
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "outputs": [],
      "execution_count": 121,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690905677593
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_dict = {\n",
        "    'max_depth': 3,\n",
        "    'n_estimators': 100,\n",
        "    'lambda' : 1,\n",
        "    'subsample' : 1,\n",
        "    'colsample_bytree': 1\n",
        "}\n",
        "model = train_model(x_train, y_train, params_dict)\n",
        "y_pred = model.predict(x_val)\n",
        "\n",
        "y_min, y_max = df['Weekly_Sales'].min(), df['Weekly_Sales'].max()\n",
        "# computing Normalized RMSE\n",
        "nrmse = np.sqrt(mean_squared_error(y_val, y_pred))/(y_max - y_min)"
      ],
      "outputs": [],
      "execution_count": 122,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690905731188
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nrmse"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 123,
          "data": {
            "text/plain": "0.001777523833815344"
          },
          "metadata": {}
        }
      ],
      "execution_count": 123,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690905737327
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Xgboost regressor"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb"
      ],
      "outputs": [],
      "execution_count": 67,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690900187707
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "kwargs = {\n",
        "    'max_depth': 3,\n",
        "    'n_estimators': 100,\n",
        "    'lambda' : 1,\n",
        "    'subsample' : 1,\n",
        "    'colsample_bytree': 1\n",
        "}\n",
        "#Define the estimator\n",
        "estimator = xgb.XGBRegressor(\n",
        "    objective = 'reg:squarederror',\n",
        "    **kwargs\n",
        "    )\n",
        "\n",
        "# Define the model\n",
        "my_model = MultiOutputRegressor(estimator = estimator, n_jobs = -1).fit(X, y)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "fit() got an unexpected keyword argument 'max_depth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[106], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m estimator \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(\n\u001b[1;32m     13\u001b[0m     objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m my_model \u001b[38;5;241m=\u001b[39m \u001b[43mMultiOutputRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'max_depth'"
          ]
        }
      ],
      "execution_count": 106,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690902526225
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.score(X, y)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 102,
          "data": {
            "text/plain": "0.9968594816576335"
          },
          "metadata": {}
        }
      ],
      "execution_count": 102,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690901685432
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb.__version__"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 103,
          "data": {
            "text/plain": "'1.3.3'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 103,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690901780751
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(\"https://storage.googleapis.com/kagglesdsdata/datasets/3186183/5526698/Walmart%20Data%20Analysis%20and%20Forcasting.csv?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230801%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230801T183427Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=5be97b22bea1d8e7561b7fd1ce98a17e7d5edddd533590bb3fe8ddb0928d70b43f611c4dc0a9c0ce3c1eec2589169823e5ac13c57635e02b9c9a6add38ba20779c28bc1f7d8c0ab987b95f5cc59b0f7bffc66aa0067861ace20a163d65049a3acd27aeef4c0014c1b57488d601654dd283b5ee4e91f348b21360732716f693499313ab7fe40066440726fcf0e94a084d93051e44a10e93aeb531b160f185c4a980b55b815105438f703949f02f2193201c0dc05491736a9861010b3a1625852539d77da9dcfb2f08d222e9414e98a9380d1267ad8ff675352a68f50c62fedcf0fdba09ecf02aefa868fe75a1195eee9102eab24d418dfd6f2a815b1470a2e9bc\")\n",
        "test.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "   Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n0      1  05-02-2010    1643690.90             0        42.31       2.572   \n1      1  12-02-2010    1641957.44             1        38.51       2.548   \n2      1  19-02-2010    1611968.17             0        39.93       2.514   \n3      1  26-02-2010    1409727.59             0        46.63       2.561   \n4      1  05-03-2010    1554806.68             0        46.50       2.625   \n\n          CPI  Unemployment  \n0  211.096358         8.106  \n1  211.242170         8.106  \n2  211.289143         8.106  \n3  211.319643         8.106  \n4  211.350143         8.106  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>Date</th>\n      <th>Weekly_Sales</th>\n      <th>Holiday_Flag</th>\n      <th>Temperature</th>\n      <th>Fuel_Price</th>\n      <th>CPI</th>\n      <th>Unemployment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>05-02-2010</td>\n      <td>1643690.90</td>\n      <td>0</td>\n      <td>42.31</td>\n      <td>2.572</td>\n      <td>211.096358</td>\n      <td>8.106</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>12-02-2010</td>\n      <td>1641957.44</td>\n      <td>1</td>\n      <td>38.51</td>\n      <td>2.548</td>\n      <td>211.242170</td>\n      <td>8.106</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>19-02-2010</td>\n      <td>1611968.17</td>\n      <td>0</td>\n      <td>39.93</td>\n      <td>2.514</td>\n      <td>211.289143</td>\n      <td>8.106</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>26-02-2010</td>\n      <td>1409727.59</td>\n      <td>0</td>\n      <td>46.63</td>\n      <td>2.561</td>\n      <td>211.319643</td>\n      <td>8.106</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>05-03-2010</td>\n      <td>1554806.68</td>\n      <td>0</td>\n      <td>46.50</td>\n      <td>2.625</td>\n      <td>211.350143</td>\n      <td>8.106</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690914947214
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}