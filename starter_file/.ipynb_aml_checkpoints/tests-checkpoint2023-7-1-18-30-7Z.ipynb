{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset, Datastore\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "\n",
        "def get_data():\n",
        "    subscription_id = 'd2706c67-acfc-4bd3-9067-3ff6ac190bc9'\n",
        "    resource_group = 'capstone-project'\n",
        "    workspace_name = 'capstone-project'\n",
        "\n",
        "    workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
        "\n",
        "    datastore = Datastore.get(workspace, \"workspaceworkingdirectory\")\n",
        "    dataset = Dataset.Tabular.from_delimited_files(path=(datastore, 'Users/hualcosa/nd00333-capstone/data/Walmart Data Analysis and Forcasting.csv'))\n",
        "    df = dataset.to_pandas_dataframe() \n",
        "    return df"
      ],
      "outputs": [],
      "execution_count": 59,
      "metadata": {
        "gather": {
          "logged": 1690898943154
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(df):\n",
        "    '''\n",
        "    This function formats the dataframe, adding past 8 weeks of sales as lagged features\n",
        "    and 4 weeks of future sales as the label column.\n",
        "\n",
        "    Return:\n",
        "    X. Training data with features + lagged sales\n",
        "    y. vector with the next 4 weeks of sales\n",
        "    '''\n",
        "    \n",
        "    df_with_windows = []\n",
        "    for store_num in df.Store.unique():\n",
        "        store_df = df[df.Store == store_num].copy()\n",
        "        # making lag features\n",
        "        for i in range(1, 9):\n",
        "            store_df[f'Weekly_Sales_t-{i}'] = store_df['Weekly_Sales'].shift(i)\n",
        "        # making future_time_steps\n",
        "        for i in range(1,4):\n",
        "            store_df[f'Weekly_Sales_t+{i}'] = store_df['Weekly_Sales'].shift(-i)\n",
        "\n",
        "        df_with_windows.append(store_df)\n",
        "\n",
        "    df_with_windows = pd.concat(df_with_windows).dropna()\n",
        "    # renaming first future value, to follow the same pattern as the other columns\n",
        "    df_with_windows.rename(columns={\"Weekly_Sales\":\"Weekly_Sales_t+0\"}, inplace=True)\n",
        "    df_with_windows = df_with_windows[['Store', 'Date', 'Holiday_Flag', 'Temperature',\n",
        "                                        'Fuel_Price', 'CPI', 'Unemployment', 'Weekly_Sales_t-1',\n",
        "                                        'Weekly_Sales_t-2', 'Weekly_Sales_t-3', 'Weekly_Sales_t-4',\n",
        "                                        'Weekly_Sales_t-5', 'Weekly_Sales_t-6', 'Weekly_Sales_t-7',\n",
        "                                        'Weekly_Sales_t-8', 'Weekly_Sales_t+0','Weekly_Sales_t+1', 'Weekly_Sales_t+2',\n",
        "                                        'Weekly_Sales_t+3']]\n",
        "\n",
        "    # separate by store, train_test_split, and then join data again\n",
        "    x_train, x_val, y_train, y_val = [], [], [], []\n",
        "\n",
        "    for store_num in df_with_windows.Store.unique():\n",
        "        store_df = df_with_windows[df_with_windows.Store == store_num].copy()\n",
        "        # future columns filter\n",
        "        ftr = store_df.columns.str.match(r'.+t\\+\\d')\n",
        "        # making label vector\n",
        "        y_store = store_df.loc[:, ftr].apply(lambda row: list(row), axis=1).tolist()\n",
        "        # convert list to numpy array format\n",
        "        y_store = np.array(y_store)\n",
        "        # making training data\n",
        "        X_store = store_df.drop(columns='Date').values\n",
        "        x_train_store, x_val_store, y_train_store, y_val_store = train_test_split(X_store, y_store, test_size=0.2, shuffle=False, random_state=96)\n",
        "        \n",
        "        # appending to final results\n",
        "        x_train.append(x_train_store)\n",
        "        x_val.append(x_val_store)\n",
        "        y_train.append(y_train_store)\n",
        "        y_val.append(y_val_store)\n",
        "\n",
        "    x_train = np.concatenate(x_train)\n",
        "    x_val = np.concatenate(x_val)\n",
        "    y_train = np.concatenate(y_train)\n",
        "    y_val = np.concatenate(y_val)\n",
        "\n",
        "    return x_train, x_val, y_train, y_val\n"
      ],
      "outputs": [],
      "execution_count": 115,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690904486219
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info('Getting data...')\n",
        "df = get_data()\n",
        "logging.info('formatting data...')\n",
        "x_train, x_val, y_train, y_val = process_data(df)"
      ],
      "outputs": [],
      "execution_count": 116,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690904497031
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 117,
          "data": {
            "text/plain": "((4725, 18), (1215, 18), (4725, 4), (1215, 4))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 117,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690904515131
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(x_train, y_train, kwargs):\n",
        "    '''\n",
        "    This function receives the processed X, y values and fits a multiple output XGBRegressor to it.\n",
        "\n",
        "    Returns: the fitted model\n",
        "    '''\n",
        "    #Define the estimator\n",
        "    estimator = xgb.XGBRegressor(\n",
        "        objective = 'reg:squarederror',\n",
        "        **kwargs\n",
        "        )\n",
        "\n",
        "    # Define the model\n",
        "    my_model = MultiOutputRegressor(estimator = estimator, n_jobs = -1)\n",
        "    my_model.fit(x_train, y_train)\n",
        "\n",
        "    return my_model"
      ],
      "outputs": [],
      "execution_count": 120,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690905612124
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "outputs": [],
      "execution_count": 121,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690905677593
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_dict = {\n",
        "    'max_depth': 3,\n",
        "    'n_estimators': 100,\n",
        "    'lambda' : 1,\n",
        "    'subsample' : 1,\n",
        "    'colsample_bytree': 1\n",
        "}\n",
        "model = train_model(x_train, y_train, params_dict)\n",
        "y_pred = model.predict(x_val)\n",
        "\n",
        "y_min, y_max = df['Weekly_Sales'].min(), df['Weekly_Sales'].max()\n",
        "# computing Normalized RMSE\n",
        "nrmse = np.sqrt(mean_squared_error(y_val, y_pred))/(y_max - y_min)"
      ],
      "outputs": [],
      "execution_count": 122,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690905731188
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nrmse"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 123,
          "data": {
            "text/plain": "0.001777523833815344"
          },
          "metadata": {}
        }
      ],
      "execution_count": 123,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690905737327
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Xgboost regressor"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb"
      ],
      "outputs": [],
      "execution_count": 67,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690900187707
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "kwargs = {\n",
        "    'max_depth': 3,\n",
        "    'n_estimators': 100,\n",
        "    'lambda' : 1,\n",
        "    'subsample' : 1,\n",
        "    'colsample_bytree': 1\n",
        "}\n",
        "#Define the estimator\n",
        "estimator = xgb.XGBRegressor(\n",
        "    objective = 'reg:squarederror',\n",
        "    **kwargs\n",
        "    )\n",
        "\n",
        "# Define the model\n",
        "my_model = MultiOutputRegressor(estimator = estimator, n_jobs = -1).fit(X, y)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "fit() got an unexpected keyword argument 'max_depth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[106], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m estimator \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(\n\u001b[1;32m     13\u001b[0m     objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m my_model \u001b[38;5;241m=\u001b[39m \u001b[43mMultiOutputRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'max_depth'"
          ]
        }
      ],
      "execution_count": 106,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690902526225
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.score(X, y)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 102,
          "data": {
            "text/plain": "0.9968594816576335"
          },
          "metadata": {}
        }
      ],
      "execution_count": 102,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690901685432
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb.__version__"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 103,
          "data": {
            "text/plain": "'1.3.3'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 103,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690901780751
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}